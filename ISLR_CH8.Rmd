---
title: "ISLR CH8 Exercises"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---

\usepackage{amsthm}

```{r classification tree}
library(tidyverse)
library(tree)
options(warn = 1)
set.seed(1)
carseats.df = read.csv("/Users/shahrdadshadab/env/my-R-project/ISLR/Data/datasets/Carseats.csv", 
                      header=T, stringsAsFactors = F, na.strings = "?")

carseats.df <- tibble(carseats.df)


# find NAs
carseats.df [rowSums (is.na(carseats.df) == T), ]

carseats.df %>% 
   filter_all(any_vars(is.na(.))) 

# convert all character columns to factor
char.to.fctor <- function(df)
  df %>%
    mutate_if(is.character, ~ factor(.x, levels = (.x %>% table() %>% names())))

carseats.df <- char.to.fctor(carseats.df)

# Add new column High as label for all records
carseats.df$High <- ifelse(carseats.df$Sales <= 8, "No", "Yes")

# convert High column into factor
carseats.df$High <- ordered(carseats.df$High, levels = c("Yes","No"))
str(carseats.df)

# construct a classification tree on data 
tree.carseats <- tree(High ~ .-Sales, carseats.df)

summary(tree.carseats)

plot(tree.carseats)
text(tree.carseats, pretty=0)

tree.carseats

```

Tree Deviance is defined as :$-2\sum_{m=1}^\overline{T_{0}} \sum_{k=1}^K n_{m,k} \ln \widehat{p}_{m,k}$

Residual mean devince is:
$\frac{-2\sum_{m=1}^\overline{T_{0}} \sum_{k=1}^K n_{m,k} \ln \widehat{p}_{m,k}}{N - |T_{0}|}$

Where N is Number of observations.

Note that values for each branch are as follows:

ShelveLoc: Good $(split\,criterion)$ 85 $(No\,of\,observation\,in\,the\,branch)$ 90.330 $(deviance)$ Yes $(overall\,prediction\,for\,the\,branch)$ (0.77647 0.22353 )  $(fractions\,of\,observation\,for\,the\,branch)$
```{r Calculate test error for above classification tree}

library(tidyverse)
library(tree)
options(warn = 1)
set.seed(1)
carseats.df = read.csv("/Users/shahrdadshadab/env/my-R-project/ISLR/Data/datasets/Carseats.csv", 
                      header=T, stringsAsFactors = F, na.strings = "?")

carseats.df <- tibble(carseats.df)


# find NAs
carseats.df [rowSums (is.na(carseats.df) == T), ]

carseats.df %>% 
   filter_all(any_vars(is.na(.))) 

# convert all character columns to factor
char.to.fctor <- function(df)
  df %>%
    mutate_if(is.character, ~ factor(.x, levels = (.x %>% table() %>% names())))

carseats.df <- char.to.fctor(carseats.df)

# Add new column High as label for all records
carseats.df$High <- ifelse(carseats.df$Sales <= 8, "No", "Yes")

# convert High column into factor
carseats.df$High <- factor(carseats.df$High, levels = c("Yes","No"))

set.seed(1113)

no.of.train <- ceiling(0.7 * nrow(carseats.df))
no.of.test <- nrow(carseats.df) - no.of.train

train.idx <- sample(seq_len(nrow(carseats.df)), no.of.train)
test.idx <- setdiff(seq_len(nrow(carseats.df)), train.idx)

# build classification tree on train data
tree.carseats <- tree(High ~ .-Sales, carseats.df[train.idx,])

plot(tree.carseats)
text(tree.carseats, pretty = 0)
# do the predoiction on test data (type="class" makes R return class predictions):
pred.probs <- predict(tree.carseats,carseats.df[test.idx,])
tree.pred <- predict(tree.carseats, carseats.df[test.idx,], type = "class")

# see the confusion matrix
library(pROC)
(confusion_table <- table(tree.pred, carseats.df[test.idx,]$High))

nullClassifier <- max(
    (confusion_table[1,1] + confusion_table[2,1])/(confusion_table[1,1] + confusion_table[2,1]+ confusion_table[1,2] + confusion_table[2,2] ), 
    (confusion_table[1,2] + confusion_table[2,2])/(confusion_table[1,1] + confusion_table[2,1]+ confusion_table[1,2] + confusion_table[2,2] ))
  
roc_obj <- roc(unlist(carseats.df[test.idx,]$High), pred.probs[, 1])

# Let's draw some AUC plots
plot(roc_obj, legacy.axes = TRUE)


missclassificationRate <- mean(tree.pred != carseats.df[test.idx,]$High)
FP_rates <- confusion_table[2,1]/(confusion_table[2,1]+ confusion_table[1,1])
TP_rates <- confusion_table[2,2]/(confusion_table[2,2]+ confusion_table[1,2])
precisions <- confusion_table[2,2] / (confusion_table[2,2] + confusion_table[2,1])
specificities <-  1 - confusion_table[2,1]/(confusion_table[2,1]+ confusion_table[1,1]) 
classification.rate <- (confusion_table[2,2] + confusion_table[1,1]) / 
  (confusion_table[1,1]+ confusion_table[1,2] + confusion_table[2,1]+ confusion_table[2,2])
# overall fraction of wrong predictions:
# print(confusion_table)

sprintf("Null Classifier error rate : %s", 1 - nullClassifier)

# average missclassification error rate
sprintf("tree classifier : Missclassification error rate : %s", missclassificationRate)

# FP rate:
sprintf("tree classifier : FP rate (TypeI error, 1 - specificity) : %s", FP_rates)

# tree classification 
print(glue::glue("Tree classification rate: ", classification.rate))

# Null classifier rate
sprintf("Null Classifier rate: %s", nullClassifier)

# TP rate:
sprintf("tree classifier : TP rate (1-TypeII error, power, sensetivity, recall) : %s", TP_rates)

# precision:
sprintf("tree classifier : precision: %s", precisions)

# specificity 1-FP/N:
sprintf("tree classifier : specificity 1-FP/N: %s", specificities)

# -----------------------------------------------------------------------------
# ---------- Lets prune the tree to see if we get better results ---------------
cv.carseats <- cv.tree(object = tree.carseats, FUN = prune.misclass, K = 10)

# Number of terminal nodes of each tree that CV considered
cv.carseats$size

# Coross validation error rate corresponding to each tree that CV considered
cv.carseats$dev

# value of tuning parameter alpha that corresponds to each tree considered by CV
cv.carseats$k

# plot the missclassification error rate as the function of size and k 
plot(cv.carseats$size, cv.carseats$dev, type = 'b')
plot(cv.carseats$k, cv.carseats$dev, type = 'b')

# seems like 9 is the best size of the tree, let's prune it to get to tree with size 9
prune.carseats <- prune.misclass(tree.carseats, best = 9)

#original data
str(carseats.df)

#pruned tree
summary(prune.carseats)

plot(prune.carseats)
text(prune.carseats, pretty = 0)
# let's run it on test set to see the ,iss classification rate again:


# do the predoiction on test data (type="class" makes R return class predictions):
pred.probs <- predict(prune.carseats,carseats.df[test.idx,])
tree.pred <- predict(prune.carseats, carseats.df[test.idx,], type = "class")

# see the confusion matrix
library(pROC)
(confusion_table <- table(tree.pred, carseats.df[test.idx,]$High))

nullClassifier <- max(
    (confusion_table[1,1] + confusion_table[2,1])/(confusion_table[1,1] + confusion_table[2,1]+ confusion_table[1,2] + confusion_table[2,2] ), 
    (confusion_table[1,2] + confusion_table[2,2])/(confusion_table[1,1] + confusion_table[2,1]+ confusion_table[1,2] + confusion_table[2,2] ))
  
roc_obj <- roc(unlist(carseats.df[test.idx,]$High), pred.probs[, 1])

# Let's draw some AUC plots
plot(roc_obj, legacy.axes = TRUE)


missclassificationRate <- mean(tree.pred != carseats.df[test.idx,]$High)
FP_rates <- confusion_table[2,1]/(confusion_table[2,1]+ confusion_table[1,1])
TP_rates <- confusion_table[2,2]/(confusion_table[2,2]+ confusion_table[1,2])
precisions <- confusion_table[2,2] / (confusion_table[2,2] + confusion_table[2,1])
specificities <-  1 - confusion_table[2,1]/(confusion_table[2,1]+ confusion_table[1,1]) 
classification.rate <- (confusion_table[2,2] + confusion_table[1,1]) / 
  (confusion_table[1,1]+ confusion_table[1,2] + confusion_table[2,1]+ confusion_table[2,2])
# overall fraction of wrong predictions:
# print(confusion_table)


sprintf("Null Classifier error rate : %s", 1 - nullClassifier)

# average missclassification error rate
sprintf("tree classifier : Missclassification error rate : %s", missclassificationRate)

# FP rate:
sprintf("tree classifier : FP rate (TypeI error, 1 - specificity) : %s", FP_rates)

# tree classification 
print(glue::glue("Tree classification rate: ", classification.rate))

# Null classifier rate
sprintf("Null Classifier: %s", nullClassifier)

# TP rate:
sprintf("tree classifier : TP rate (1-TypeII error, power, sensetivity, recall) : %s", TP_rates)

# precision:
sprintf("tree classifier : precision: %s", precisions)

# specificity 1-FP/N:
sprintf("tree classifier : specificity 1-FP/N: %s", specificities)

```


Remember to each given value of $\alpha$  (k in R) we assign a subtree $T_{\alpha}$ as below:  
Using \space Gini \space index:  
$T_{\alpha} = \underset{T \subset T_{0}}{\operatorname{argMin}} \{\sum\limits_{i=1}^{|T|} \sum\limits_{k=1}^{K} \hat{p_{m,k}} \cdot (1 -  \hat{p_{m,k})} + \alpha \cdot |T| \space\space | T \subset T_{0} \}$

or \space using  \space Cross  \space Entropy:  

$T_{\alpha} = \underset{T \subset T_{0}}{\operatorname{argMin}} \{\sum\limits_{i=1}^{|T|} \sum\limits_{k=1}^{K} \hat{-p_{m,k}} \cdot \log  (\hat{p_{m,k}}) + \alpha \cdot |T| \space\space | T \subset T_{0} \}$

And then we use CV to find few good values of $\alpha$ and their corresponding $T_{\alpha}$ based on 
miss classification error rate (FUN = prune.misclass).

```{r Fit Regression tree to Boston data set}
library(tidyverse)
library(dataPreparation)
library(tree)
boston.df = read.csv(
  "/Users/shahrdadshadab/env/my-R-project/ISLR/Data/datasets/BostonHousing.csv", 
  header=T, stringsAsFactors = F, na.strings = "?")

boston.df <- tibble(boston.df)

# see if there is any NA in any records
nrow(df[which(is.na(boston.df)),])

# No NA anywhere , let's do usual clean up:

# remove constant variables
constant_cols <- whichAreConstant(boston.df)

# remove Variables that are in double (for example col1 == col2)
(double_cols <- whichAreInDouble(boston.df))

# remove Variables that are exact bijections (for example col1 = A, B, B, A and col2 = 1, 2, 2, 1)
(bijections_cols <- whichAreBijection(boston.df))

str(boston.df)

set.seed(1113)
no.of.train <- ceiling(0.7 * nrow(boston.df))
no.of.test <- nrow(boston.df) - no.of.train

train.idx <- sample(seq_len(nrow(boston.df)), no.of.train)
test.idx <- setdiff(seq_len(nrow(boston.df)), train.idx)

tree.boston <- tree(medv ~ ., boston.df, subset = train.idx)

plot(tree.boston)
text(tree.boston, pretty = 0)

tree.boston

# let's draw the residuals pdf, very close to standard normal
plot(density(summary(tree.boston)$residuals))

# deviance is sum of squared error for the tree

# do the predoiction on test data 
pred.values <- predict(tree.boston, newdata = boston.df[test.idx,])
obs.values <- boston.df[test.idx,]$medv
# find the R^2 for test data
(R.squared <- round((cor(pred.values, obs.values) ^ 2), 3))


# now plot the observed vs predicted on test data
plot.data <- data.frame("Pred.values" = pred.values, "obs.values" = obs.values, 
                                "DataSet" = "test")
residuals <- obs.values - pred.values

plot.residuals <- data.frame("x" = obs.values, "y" = pred.values, 
                "x1" = obs.values, "y2" = pred.values + residuals,
                "DataSet" = "test")

ggplot() + 
        # plot test samples
        geom_point(data = plot.data, 
            aes(x = obs.values, y = pred.values, color = DataSet)) +
        # plot residuals
        geom_segment(data = plot.residuals, alpha = 0.2,
            aes(x = x, y = y, xend = x1, yend = y2, group = DataSet)) +
        # plot optimal regressor
        geom_abline(color = "blue", slope = 1)

# plot the residuals
plot(density(residuals))

plot(pred.values, obs.values)
abline(0,1)

# tetMSE
mean((obs.values - pred.values)^2)

#---------------------------------------------------------
# Now let's prune the tree to see if it performs better
# --------------------------------------------------------
cv.boston <- cv.tree(tree.boston, K = 10)
plot(cv.boston$size, cv.boston$dev, type='b')

# The deviance is lowest at 7, so let's construct a pruned tree with 7 nodes
prune.boston <- prune.tree(tree = tree.boston, best=7)

# summary of pruned tree
summary(prune.boston)

plot(prune.boston)
text(prune.boston, pretty = 0)

# let's draw the residuals pdf for pruned tree
plot(density(summary(prune.boston)$residuals))

# do the predoiction on test data 
pred.values <- predict(prune.boston, newdata = boston.df[test.idx,])
obs.values <- boston.df[test.idx,]$medv
# find the R^2 for test data
(R.squared <- round((cor(pred.values, obs.values) ^ 2), 3))


# now plot the observed vs predicted on test data
plot.data <- data.frame("Pred.values" = pred.values, "obs.values" = obs.values, 
                                "DataSet" = "test")
residuals <- obs.values - pred.values

plot.residuals <- data.frame("x" = obs.values, "y" = pred.values, 
                "x1" = obs.values, "y2" = pred.values + residuals,
                "DataSet" = "test")

ggplot() + 
        # plot test samples
        geom_point(data = plot.data, 
            aes(x = obs.values, y = pred.values, color = DataSet)) +
        # plot residuals
        geom_segment(data = plot.residuals, alpha = 0.2,
            aes(x = x, y = y, xend = x1, yend = y2, group = DataSet)) +
        # plot optimal regressor
        geom_abline(color = "blue", slope = 1)

# plot the residuals
plot(density(residuals))

plot(pred.values, obs.values)
abline(0,1)

# tetMSE
mean((obs.values - pred.values)^2)

# seemed like pruning downgraded the performance of the model 
# So pruning the tree does not add to performance

# From another perspective since testMSE ~ 25 then we can infere that 
# real house price is 5k around home value in suberb 
```

  
```{r}
# library("lme4")
# library("glmmADMB")      ## (not on CRAN)
# library("glmmTMB")
# library("MCMCglmm")
# library("blme")
# library("MASS")          ## for glmmPQL (base R)
# library("nlme")          ## for intervals(), tundra example (base R)
# ## auxiliary
# library("ggplot2")       ## for pretty plots generally
# ## ggplot customization:
# theme_set(theme_bw())
# scale_colour_discrete <- function(...,palette="Set1") {
#     scale_colour_brewer(...,palette=palette)
# }
# scale_colour_orig <- ggplot2::scale_colour_discrete
# scale_fill_discrete <- function(...,palette="Set1") {
#     scale_fill_brewer(...,palette=palette)
# }
# ## to squash facets together ...
# zmargin <- theme(panel.spacing=grid::unit(0,"lines"))
# library("gridExtra")     ## for grid.arrange()
# library("broom.mixed")
# ## n.b. as of 25 Sep 2018, need bbolker github version of dotwhisker ...
# library("dotwhisker")
# library("coda")      ## MCMC diagnostics
# library("aods3")     ## overdispersion diagnostics
# library("plotMCMC") ## pretty plots from MCMC fits
# library("bbmle")     ## AICtab
# library("pbkrtest")  ## parametric bootstrap
# library("Hmisc")
# ## for general-purpose reshaping and data manipulation:
# library("reshape2")
# library("plyr")
# ## for illustrating effects of observation-level variance in binary data:
# library("numDeriv")
# library("glmmADMB")
# bb <- glmmADMB:::get_bin_loc()[["bin_loc"]]
# bpath <- gsub("glmmadmb$","",bb)
# file.copy(bb,paste0(bpath,"glmmadmb.bak"))
# bburl <- "http://admb-project.org/buildbot/glmmadmb/"
# download.file(paste0(bburl,
#    "glmmadmb-mingw64-r2885-windows8-mingw64.exe"), dest=bb)
```

